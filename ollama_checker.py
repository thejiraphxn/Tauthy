import requests
import json
import re
import pandas as pd
import random
from langdetect import detect_langs

def detect_language(text):
    try:
        langs = detect_langs(text)
        if langs and langs[0].prob >= 0.9:
            return langs[0].lang
    except:
        pass
    return "unknown"

def clamp_confidence(ai, human):
    total = ai + human
    if total == 0:
        return 50.0, 50.0
    ai_norm = ai / total * 100
    ai_clamped = max(min(ai_norm, 99.0), 1.0)
    human_clamped = 100.0 - ai_clamped
    return round(ai_clamped, 2), round(human_clamped, 2)

def filter_by_language(df, lang, n_each=20):
    # üîπ ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏¢‡∏≠‡∏∞‡πÜ ‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö lang
    ai_pool = df[df['label'] == 'ai'].sample(n=100, random_state=1)['text'].tolist()
    human_pool = df[df['label'] == 'human'].sample(n=100, random_state=2)['text'].tolist()

    def filter_lang(pool):
        filtered = []
        for t in pool:
            if detect_language(t) == lang:
                filtered.append(t)
            if len(filtered) >= n_each:
                break
        return filtered

    ai_filtered = filter_lang(ai_pool)
    human_filtered = filter_lang(human_pool)

    if len(ai_filtered) < n_each or len(human_filtered) < n_each:
        raise ValueError(f"Not enough {lang} examples in train.csv")

    return ai_filtered, human_filtered

def query_ollama(text):
    # üîπ ‡∏ï‡∏£‡∏ß‡∏à‡∏†‡∏≤‡∏©‡∏≤‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
    lang_input = detect_language(text)
    print(f"Detected input language: {lang_input}")

    if lang_input == "unknown":
        raise ValueError("Cannot detect language confidently.")

    df = pd.read_csv("data/train.csv")

    ai_examples, human_examples = filter_by_language(df, lang_input)

    reference_examples = "\n\n".join(
        [f"[AI EXAMPLE {i+1}]: {ex}" for i, ex in enumerate(ai_examples)] +
        [f"[HUMAN EXAMPLE {i+1}]: {ex}" for i, ex in enumerate(human_examples)]
    )
    
    print(reference_examples)

    prompt = (
        "You are an advanced linguistic analyst specializing in detecting whether texts are human-written "
        "or generated by Large Language Models (such as GPT, LLaMA, Mistral, Claude, etc.). Your analysis "
        "will directly influence critical decisions on a global platform used by millions of users.\n\n"

        "You will receive REFERENCE EXAMPLES carefully selected to represent linguistic patterns typical "
        "of human writing and AI-generated texts IN THE SAME LANGUAGE as the TARGET TEXT. Examine them thoroughly.\n\n"

        "==================\n"
        "REFERENCE EXAMPLES\n"
        "==================\n\n"
        f"{reference_examples}\n\n"

        "==================\n"
        "ANALYSIS INSTRUCTIONS\n"
        "==================\n"
        "Analyze the TARGET TEXT focusing strictly on the following linguistic and stylistic indicators:\n\n"

        "1. **Syntactic Patterns and Structure:**\n"
        "   - AI-generated texts often exhibit overly uniform or repetitive sentence structures and perfect grammar.\n"
        "   - Human texts typically show natural variability, including occasional informal phrasing, grammatical errors, and mixed sentence lengths.\n\n"

        "2. **Lexical Appropriateness and Vocabulary Usage:**\n"
        "   - AI-generated texts frequently misuse advanced, technical, or formal vocabulary in inappropriate contexts or may repeat unusual terms excessively.\n"
        "   - Human writers use contextually appropriate vocabulary, idiomatic expressions, slang, and subtle word variations naturally.\n\n"

        "3. **Semantic Coherence and Logical Flow:**\n"
        "   - AI-generated texts can display unnatural topic shifts, repeated filler content, overly explicit clarifications, or logically coherent but contextually irrelevant details.\n"
        "   - Human texts, even if tangential, maintain contextual relevance and logical consistency at a deeper level.\n\n"

        "4. **Style, Intent, and Pragmatic Purpose:**\n"
        "   - Human-written texts exhibit clear communicative intent, context-driven emotions, humor, irony, or pragmatically purposeful language.\n"
        "   - AI-generated texts might imitate stylistic elements superficially but often lack genuine pragmatic purpose, emotional authenticity, or nuance.\n\n"

        "5. **Special Cases and Edge Scenarios:**\n"
        "   - Extremely short texts (less than one sentence) or texts composed mostly of emojis or special characters may indicate human authorship unless unusually uniform or repetitive.\n"
        "   - Texts with overt hallucinations, factual inconsistencies, or clearly unnatural repetitions strongly suggest AI generation.\n\n"

        "==================\n"
        "CONFIDENCE THRESHOLD & EDGE CASE HANDLING\n"
        "==================\n"
        "- Only return a definitive classification if you have at least 75% confidence in your analysis.\n"
        "- Never return exactly 0% or 100% for either class. Even if you are highly confident, keep values within the range of 1.00% to 99.00%.\n"
        "- If you are unsure (confidence less than 75%), label confidence percentages accordingly and mention uncertainty in the reason.\n"

        "==================\n"
        "EXAMPLE OUTPUT FORMAT\n"
        "==================\n"
        "Example:\n"
        "{\n"
        "  \"ai\": 88.5,\n"
        "  \"human\": 11.5,\n"
        "  \"reason\": \"Text shows robotic phrasing and consistent structure (Point 1). Vocabulary was overly formal (Point 2).\"\n"
        "}\n\n"

        "==================\n"
        "RESPONSE FORMAT (STRICT)\n"
        "==================\n"
        "Respond strictly with ONLY a JSON object following this exact format, without ANY additional text or explanation:\n\n"
        "{\n"
        "  \"ai\": <confidence_percentage>,\n"
        "  \"human\": <confidence_percentage>,\n"
        "  \"reason\": \"Detailed linguistic explanation explicitly referencing the analysis indicators above.\"\n"
        "}\n\n"

        "==================\n"
        "TARGET TEXT TO ANALYZE\n"
        "==================\n"
        f"{text}\n\n"

        "Now, respond ONLY with the JSON object as specified."
    )


    try:
        response = requests.post(
            "http://localhost:11434/api/generate",
            json={
                "model": "llama3.2",
                "prompt": prompt,
                "stream": False
            }
        )

        raw = response.json().get("response", "").strip()
        json_str = re.search(r'\{.*\}', raw, re.DOTALL)

        if json_str:
            data = json.loads(json_str.group())

            # üîπ ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏à‡∏≤‡∏Å model
            ai_raw = float(data.get("ai", 0.0))
            human_raw = float(data.get("human", 0.0))

            # üîπ ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 1‚Äì99 ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô 100
            ai, human = clamp_confidence(ai_raw, human_raw)

            return {
                "ai": ai,
                "human": human,
                "reason": data.get("reason", "No reason provided."),
                "raw": raw
            }

        else:
            return {
                "ai": 0.0,
                "human": 0.0,
                "reason": "No valid JSON object found.",
                "raw": raw
            }

    except Exception as e:
        return {
            "ai": 0.0,
            "human": 0.0,
            "reason": f"Error or malformed JSON: {e}",
            "raw": ""
        }
